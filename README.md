# ğŸ¥ Medical Chatbot with RAG

A medical chatbot based on **TinyLlama** and **Llama 3.1**, combined with **Retrieval-Augmented Generation (RAG)** for precise, context-aware answers.

---

## ğŸŒŸ Features
- ğŸ’¬ **Web-based chatbot** (Gradio)
- ğŸ§  **RAG-based**: Local knowledge + cloud generation
- ğŸ“š **Learning mode**: Stores new insights from conversations
- ğŸ› ï¸ **Admin interface**: Manage the knowledge base
- ğŸ”’ **Privacy**: Local retrieval, no external storage

---

## ğŸ§° Requirements
- Python **3.10+**
- At least **8 GB RAM**
- (Optional) GPU for better performance
- Hugging Face account + token: [Settings â†’ Tokens](https://huggingface.co/settings/tokens)

---

## ğŸš€ Installation & Quickstart

### 1. Clone the repository
```bash
git clone <your-repo-link>
cd medical_chatbot
```

### 2. Create virtual environment
```bash
python -m venv venv
source venv/bin/activate   # Linux/Mac
venv\Scripts\activate      # Windows
```

### 3. Install dependencies
```bash
pip install -r requirements.txt
```

### 4. Set Hugging Face token
```bash
export HF_TOKEN=hf_xxxxxxxxxxxxxxxx   # Linux/Mac
setx HF_TOKEN hf_xxxxxxxxxxxxxxxx     # Windows
```

### 5. Start application
- ğŸŒ **Web interface**  
  ```bash
  python web_rag_llama3.py
  ```

- ğŸ› ï¸ **Admin interface**  
  ```bash
  python admin_interface.py
  ```

---

## ğŸ§ª Usage

### Chatbot commands
- Normal question: `What is the flu?`
- Store knowledge: `learn this` after a response

### Admin interface
- List all entries  
- Add new entries  
- Delete entries  
- Search the knowledge base  

---

## ğŸ“ Project structure
```
medical_chatbot/
â”œâ”€â”€ README.md               # This file
â”œâ”€â”€ requirements.txt        # Dependencies
â”œâ”€â”€ medical_data.json       # Example data
â”œâ”€â”€ train_medical_bot.py    # Optional training
â”œâ”€â”€ chatbot_cli.py          # Console chatbot
â”œâ”€â”€ chatbot_web.py          # Simple web interface
â”œâ”€â”€ hybrid_rag.py           # RAG with local retrieval
â”œâ”€â”€ web_rag_llama3.py       # Main web interface (Llama 3.1)
â”œâ”€â”€ admin_interface.py      # Admin tool
â””â”€â”€ chroma_db/              # Local vector database
```

---

## ğŸ§  Model information
- **Embedding**: `all-MiniLM-L6-v2` (local)  
- **Generative**: `meta-llama/Llama-3.1-8B-Instruct` (cloud)  
- **Optional pretraining**: `SpookyFab/tinyllama-pretrained-custom`  

ğŸ‘‰ To gain access: open [Llama-3.1-8B-Instruct](https://huggingface.co/meta-llama/Llama-3.1-8B-Instruct) and accept the usage terms.

---

## ğŸ“š Data sources
- Public medical datasets  
- Wikipedia (medical chapters)  
- Own experiences via learning mode  

---

## ğŸ›¡ï¸ Privacy
- Retrieval runs **locally**  
- Questions are not permanently stored  
- Answers are not externally archived  
- Learning mode only saves explicitly approved content  

---

## ğŸ§¾ Next steps
- Extend with more medical data  
- Build expert bots for other domains (law, technology, etc.)  
- Deploy to the cloud (AWS, Google Cloud)  
- Provide API interface  

---

## ğŸ¤ Contributing
1. Fork the repo  
2. Create a branch: `feature/NewFeature`  
3. Commit your changes  
4. Open a pull request  

---

## ğŸ“„ License
MIT License â€“ see [LICENSE](LICENSE)  

---

## ğŸ“ Contact
Questions or issues? â†’ [Create an issue](../../issues)
